{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Information retrieval\n",
    "The data is coming from TXT, CSV and JSON files that contain the tickers for a stock exchange. The observed exchanges are the NASDAQ, NYSE, AMEX, FSE, Bolsa de Madrid, London SE, Toronto SE, Tokyo SE."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "headers1 = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "# alternative header\n",
    "headers2 = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing: get the ticker data to download"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# NASDAQ, NYSE, AMEX\n",
    "for exchange in ['amex', 'nyse', 'nasdaq']:\n",
    "    with open(f'02_data_ticker/{exchange}.json') as f:\n",
    "        if exchange == 'amex':\n",
    "            amex = json.load(f)\n",
    "        elif exchange == 'nyse':\n",
    "            nyse = json.load(f)\n",
    "        elif exchange == 'nasdaq':\n",
    "            nasdaq = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Frankfurt Stock Exchange (FSE)\n",
    "fse = []\n",
    "with open('02_data_ticker/frankfurt.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # omit the header row\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        # access the string in the list and split the entries\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            # add \".de\" otherwise it is not find on Yahoo Finance\n",
    "            ticker = entry[1] + \".de\"\n",
    "            fse.append([entry[2], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Bolsa de Madrid\n",
    "madrid = []\n",
    "with open('02_data_ticker/madrid.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            ticker = entry[4][:-1] + \".mc\"\n",
    "            madrid.append([entry[0], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# London Stock Exchange (LSE)\n",
    "lse = []\n",
    "with open('02_data_ticker/london.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            ticker = entry[4][:-1] + \".l\"\n",
    "            lse.append([entry[0], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Toronto Stock Exchange (TSE)\n",
    "toronto = []\n",
    "with open('02_data_ticker/toronto_se.txt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    # omit the first rows\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            entry = row[0].split(\"\\t\")\n",
    "            ticker = entry[0]\n",
    "            sep = ':'\n",
    "            stripped = ticker.split(sep, maxsplit=1)[0]\n",
    "            ticker = stripped + \".TO\"\n",
    "            toronto.append([entry[1], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Tokyo Stock Exchange (TSE)\n",
    "tokyo = []\n",
    "with open('02_data_ticker/tokyo_se.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            ticker = row[0][3:] + \".T\"\n",
    "            tokyo.append([row[1], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the ticker variables from Yahoo Finance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# options for tickers: amex, nyse, nasdaq, fse, madrid, lse, toronto, tokyo\n",
    "tickers = fse\n",
    "url = 'https://finance.yahoo.com/quote/{}/profile?p={}'\n",
    "data = []\n",
    "count = 1\n",
    "\n",
    "for row in tickers:\n",
    "    try:\n",
    "        symbol = row[1]\n",
    "        response = requests.get(url.format(symbol, symbol),headers=headers1)  # url profile website is scraped\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        pattern = re.compile(r'\\s--\\sData\\s--\\s')\n",
    "        script_data = soup.find('script', text=pattern).contents[0]\n",
    "        start = script_data.find(\"context\")-2\n",
    "        json_data = json.loads(script_data[start:-12])\n",
    "\n",
    "        sector = json_data['context']['dispatcher']['stores']['QuoteSummaryStore']['assetProfile']['sector']\n",
    "        description = json_data['context']['dispatcher']['stores']['QuoteSummaryStore']['assetProfile']['longBusinessSummary']\n",
    "\n",
    "        data.append({\"name\": row[0], \"ticker\": row[1], 'sector': sector,\"description\": description})\n",
    "        print(\"added: \", row[0])\n",
    "        count += 1\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(\"not found: \", row[0])\n",
    "        pass\n",
    "\n",
    "print(\"Results:\", len(tickers), \"tickers\" , count, \"added and\", len(tickers)-count, \"not found\")\n",
    "\n",
    "# save the data list into a JSON file\n",
    "with open(f'data/{tickers}.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspection of the downloaded data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'name': 'ABCAM PLC',\n 'ticker': 'ABC.l',\n 'sector': 'Healthcare',\n 'description': 'Abcam plc, a life science company, focuses on identifying, developing, and distributing reagents and tools for scientific research, diagnostics, and drug discovery. Its principal products include primary and secondary antibodies; conjugated antibodies and conjugation kits; singleplex and multiplex immunoassays; proteins and peptides that include cytokines; edited cell lines and lysates; and various other products, including cellular activity kits, miRNA kits, biochemicals, and cell signaling pathway tools. The company serves scientists and researchers in academic institutions and research institutes, as well as in pharmaceutical, biotechnology, and diagnostics companies. It has operations in the Americas, Europe, the Middle East, Africa, China, Japan, and rest of the Asia Pacific. The company sells its products online. Abcam plc was incorporated in 1998 and is headquartered in Cambridge, the United Kingdom.'}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'london'\n",
    "with open (f'04_extracted_data/{file}.json', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(type(data))\n",
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consolidate datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amex.json\n",
      "frankfurt.json\n",
      "london.json\n",
      "madrid.json\n",
      "nasdaq1.json\n",
      "nasdaq2.json\n",
      "nyse.json\n",
      "tokyo.json\n",
      "toronto.json\n",
      "extracted company descriptions and sectors:  9856\n"
     ]
    }
   ],
   "source": [
    "path_to_json = 'C:\\\\Users\\\\esse\\\\OneDrive\\\\Dokumente\\\\GitHub\\\\project_NLP\\\\04_extracted_data\\\\'\n",
    "\n",
    "final_list = []\n",
    "\n",
    "for file_name in [file for file in os.listdir(path_to_json) if file.endswith('.json')]:\n",
    "    print(file_name)\n",
    "    with open(path_to_json + file_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for i in data:\n",
    "            final_list.append(i)\n",
    "\n",
    "print(\"extracted company descriptions and sectors: \", len(final_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "with open('data_raw.json', 'w') as f:\n",
    "    json.dump(final_list, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}