{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Information retrieval\n",
    "The data is coming from TXT, CSV and JSON files that contain all tickers at a Stock Exchange. The observed exchanges are the NASDAQ, NYSE, AMEX, FSE, Bolsa de Madrid, London, Toronto, Tokyo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "headers1 = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "headers2 = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preprocessing: get the ticker data to download"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# NASDAQ, NYSE, AMEX\n",
    "for exchange in ['amex', 'nyse', 'nasdaq']:\n",
    "    with open(f\"data_ticker/{exchange}.json\") as f:\n",
    "        if exchange == 'amex':\n",
    "            amex = json.load(f)\n",
    "        elif exchange == 'nyse':\n",
    "            nyse = json.load(f)\n",
    "        elif exchange == 'nasdaq':\n",
    "            nasdaq = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Frankfurt Stock Exchange (FSE)\n",
    "fse = []\n",
    "with open(\"data_ticker/frankfurt.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    # omit the header row\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        # access the string in the list and split the entries\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            # add \".de\" otherwise it is not find on Yahoo Finance\n",
    "            ticker = entry[1] + \".de\"\n",
    "            fse.append([entry[2], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Bolsa de Madrid\n",
    "madrid = []\n",
    "with open(\"data_ticker/madrid.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            ticker = entry[4][:-1] + \".mc\"\n",
    "            madrid.append([entry[0], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# London Stock Exchange (LSE)\n",
    "lse = []\n",
    "with open(\"data_ticker/london.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        entry = row[0].split(';')\n",
    "        try:\n",
    "            ticker = entry[4][:-1] + \".e\"\n",
    "            lse.append([entry[0], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Toronto Stock Exchange (TSE)\n",
    "toronto = []\n",
    "with open(\"data_ticker/toronto_se.txt\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    # omit the first rows\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            entry = row[0].split(\"\\t\")\n",
    "            ticker = entry[0]\n",
    "            sep = ':'\n",
    "            stripped = ticker.split(sep, maxsplit=1)[0]\n",
    "            ticker = stripped + \".TO\"\n",
    "            toronto.append([entry[1], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Tokyo Stock Exchange (TSE)\n",
    "tokyo = []\n",
    "with open(\"data_ticker/tokyo_se.csv\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            ticker = row[0][3:] + \".T\"\n",
    "            tokyo.append([row[1], ticker])\n",
    "\n",
    "        except IndexError as e:\n",
    "            print(e, row)\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the ticker variables from Yahoo Finance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# amex, nyse, nasdaq, fse, madrid, lse, toronto, tokyo\n",
    "tickers = amex\n",
    "url = 'https://finance.yahoo.com/quote/{}/profile?p={}'\n",
    "data = []\n",
    "count = 1\n",
    "\n",
    "for row in tickers:\n",
    "    try:\n",
    "        symbol = row[1]\n",
    "        response = requests.get(url.format(symbol, symbol),headers=headers1)  # url profile website is scraped\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        pattern = re.compile(r'\\s--\\sData\\s--\\s')\n",
    "        script_data = soup.find('script', text=pattern).contents[0]\n",
    "        start = script_data.find(\"context\")-2\n",
    "        json_data = json.loads(script_data[start:-12])\n",
    "\n",
    "        sector = json_data['context']['dispatcher']['stores']['QuoteSummaryStore']['assetProfile']['sector']\n",
    "        description = json_data['context']['dispatcher']['stores']['QuoteSummaryStore']['assetProfile']['longBusinessSummary']\n",
    "\n",
    "        data.append({\"name\": row[0], \"ticker\": row[1], 'sector': sector,\"description\": description})\n",
    "        print(\"added: \", row[0])\n",
    "        count += 1\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(\"not found: \", row[0])\n",
    "        pass\n",
    "\n",
    "print(\"Results:\", len(tickers), \"tickers\" , count, \"added and\", len(tickers)-count, \"not found\")\n",
    "\n",
    "# save the data list into a JSON file\n",
    "with open(f'data/{tickers}.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation of the downloaded data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open ('data/tokyo.json', encoding='utf8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(type(data))\n",
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consolidate datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_json = 'C:\\\\Users\\\\esse\\\\OneDrive\\\\Dokumente\\\\studium\\\\semester2\\\\NLP\\\\project\\\\data\\\\'\n",
    "\n",
    "final_list = []\n",
    "\n",
    "for file_name in [file for file in os.listdir(path_to_json) if file.endswith('.json')]:\n",
    "    print(file_name)\n",
    "    with open(path_to_json + file_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for i in data:\n",
    "            final_list.append(i)\n",
    "\n",
    "print(len(final_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('data/data_complete.json', 'w') as f:\n",
    "    json.dump(final_list, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}